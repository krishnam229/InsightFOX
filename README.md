# InsightFOX ğŸ¦Š â€“ Your Smart Research Assistant

## ğŸ“Œ Overview

**InsightFOX** is an AI-powered research assistant designed to fetch real-time news results, summarize them using a local LLM (LLaMA 3.2 via Ollama), and provide relevance-based star ratings. Built as a final project for **CS676 â€“ Algorithms for Data Science**, it offers a lightweight interface for fast, informed insights.

---

## ğŸš€ Features

- ğŸ” Real-Time Web Search (via DuckDuckGo + Selenium)
- ğŸ¤– Local LLM Integration (Ollama running LLaMA 3.2)
- ğŸ§  Contextual Answer Generation
- â­ Article Rating System (AI-evaluated)
- ğŸ”Š Text-to-Speech Responses (gTTS)
- âš¡ FastAPI Backend for Decoupled Logic
- ğŸ¨ Clean Streamlit UI with Star Ratings + Audio Playback

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|----------|------------|
| Frontend | Streamlit |
| Backend | FastAPI, Python |
| AI Model | Ollama (LLaMA 3.2) |
| Scraping | Selenium, BeautifulSoup |
| Audio | Google Text-to-Speech (gTTS) |

---

## ğŸ§© Project Structure

```
InsightFOX/
â”‚
â”œâ”€â”€ .idea/                  # IDE config
â”œâ”€â”€ logger/                 # Logging setup
â”‚   â””â”€â”€ app_logger.py
â”œâ”€â”€ app.py                  # Streamlit frontend
â”œâ”€â”€ api.py                  # FastAPI backend for chat + search
â”œâ”€â”€ helper.py               # Core logic: LLM + scraping + rating
â”œâ”€â”€ output.mp3              # Audio output from gTTS
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project documentation
```

---

## âš™ï¸ Setup Instructions

### ğŸ“¦ Prerequisites

- Python 3.8+
- pip
- Chrome & ChromeDriver (compatible version)
- Ollama installed locally with `llama3.2` pulled

### âœ… Installation

```bash
# Clone the repository
git clone https://github.com/krishnam229/InsightFOX.git
cd InsightFOX

# (Optional) Create virtual environment
python -m venv venv
venv\Scripts\activate     # On Windows
# or
source venv/bin/activate  # On macOS/Linux

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ§  Running the Project

### 1. Start the FastAPI server

```bash
uvicorn api:app --reload
```

### 2. Launch the Streamlit frontend

In a new terminal:

```bash
streamlit run app.py
```

---

## ğŸ§ª How It Works

1. **User enters a query** in the chat UI.
2. **DuckDuckGo** is scraped for latest results.
3. Each article is **summarized and rated** using the local LLaMA 3.2 model.
4. Top results are displayed with **star ratings** and AI-generated insights.
5. **Text-to-Speech** support reads the answer aloud.

---

## ğŸ” API Endpoints

| Method | Route              | Description                      |
|--------|--------------------|----------------------------------|
| `GET`  | `/chat-response`   | LLM-generated answer from prompt |
| `POST` | `/search-news`     | DuckDuckGo article summaries     |

---

## â— Troubleshooting

- **LLM issues?** Make sure Ollama is installed and the `llama3.2` model is pulled:
  ```bash
  ollama pull llama3.2
  ```
- **WebDriver errors?** Update ChromeDriver to match your browser version.
- **Text-to-speech not working?** Ensure `gTTS` has internet access to generate MP3s.

---

## ğŸ‘¨â€ğŸ’» Contributors

- Krishna Kirit Maniyar [@krishnam229](https://github.com/krishnam229)
- Kethan Dosapati [@DKethan](https://github.com/DKethan)

---

## ğŸ“¬ Contact

ğŸ“§ maniyarkrishna5@gmail.com  
ğŸ“˜ Created for Pace University | MS in Data Science

---

## ğŸ“„ License

MIT License â€“ free to modify and use with attribution.